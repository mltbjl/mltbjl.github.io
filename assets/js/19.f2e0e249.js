(window.webpackJsonp=window.webpackJsonp||[]).push([[19],{409:function(s,t,a){"use strict";a.r(t);var e=a(2),r=Object(e.a)({},(function(){var s=this,t=s._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("p",[s._v("该篇文章参考 "),t("a",{attrs:{href:"https://mp.weixin.qq.com/s/i6FL1iRECiWZ1CCf_juxQQ",target:"_blank",rel:"noopener noreferrer"}},[s._v("小林coding"),t("OutboundLink")],1),s._v(" ，同时"),t("a",{attrs:{href:"https://www.jianshu.com/p/cf5d381ef637",target:"_blank",rel:"noopener noreferrer"}},[s._v("建表语句参考这个博主"),t("OutboundLink")],1),s._v("；我建立的表的数据是 "),t("strong",[s._v("400w+")]),s._v("。")]),s._v(" "),t("h2",{attrs:{id:"前言"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#前言"}},[s._v("#")]),s._v(" 前言")]),s._v(" "),t("p",[t("code",[s._v("MySQL")]),s._v(" 分页有什么性能问题？如何优化？")]),s._v(" "),t("p",[s._v("既然我们有了建表语句，我就不重复了，这里我只说明一下："),t("code",[s._v("id")]),s._v(" 为我们的聚簇索引，即主键；"),t("code",[s._v("person_id")]),s._v(" 为普通索引，也为非聚簇索引；")]),s._v(" "),t("p",[s._v("要想实现分页，很容易联想到我们 "),t("code",[s._v("MySQL")]),s._v(" 提供的 "),t("code",[s._v("limit")]),s._v(" 字段，这里我们复习一下，"),t("code",[s._v("limit")]),s._v(" 字段的用法："),t("a",{attrs:{href:"https://mmbiz.qpic.cn/mmbiz_png/AnAgeMhDIiak10WxVpianzxZicJKTb4Kg74LvjrBh7xiadCuBXbe6aSdBKWQiaVC6iaO6A7qCaJx3GpqpLdhHR39WZrw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1",target:"_blank",rel:"noopener noreferrer"}},[s._v("图片"),t("OutboundLink")],1)]),s._v(" "),t("div",{staticClass:"language-sql line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- offset 为偏移量；size 是取出条目")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- 比如说 limit 0,10 就是说从第一条开始，一共展示10条数据")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("limit")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("offset")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("size\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br")])]),t("p",[s._v("OK，既然知道这个 "),t("code",[s._v("limit")]),s._v(" 的用法，我们尝试使用一下：")]),s._v(" "),t("p",[s._v("小试牛刀，我们获取第一页的数据，每页十条：")]),s._v(" "),t("div",{staticClass:"language-sql line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" t1 "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("order")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("by")]),s._v(" id "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("limit")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- 或者")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" t1 "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("order")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("by")]),s._v(" id "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("limit")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br")])]),t("p",[s._v("第一百页就是：")]),s._v(" "),t("div",{staticClass:"language-sql line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" t1 "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("order")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("by")]),s._v(" id "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("limit")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("990")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("问题来了，同样都是拿 10 条数据，查询第 1 页和第 100 页的速度一样否？why？")]),s._v(" "),t("h2",{attrs:{id:"sql-语句的执行过程"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#sql-语句的执行过程"}},[s._v("#")]),s._v(" SQL 语句的执行过程")]),s._v(" "),t("p",[t("a",{attrs:{href:"https://mmbiz.qpic.cn/mmbiz_png/AnAgeMhDIiak10WxVpianzxZicJKTb4Kg74FUeAWfaCOvicElrZiasM9TodjcTCqJ8WV3PSTl4EEHSy1Nob6icNBao7g/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1",target:"_blank",rel:"noopener noreferrer"}},[s._v("图片"),t("OutboundLink")],1)]),s._v(" "),t("p",[t("code",[s._v("MySQL")]),s._v(" 内部分为 "),t("code",[s._v("Server")]),s._v(" 层以及存储引擎层，一般情况下都用 "),t("code",[s._v("innoDB")]),s._v(" 存储引擎；")]),s._v(" "),t("p",[s._v("简单说一下这个取数据的过程，客户端执行 "),t("code",[s._v("SQL")]),s._v("语句，"),t("code",[s._v("Server")]),s._v(" 层进行对客户端发来的 "),t("code",[s._v("SQL")]),s._v(" 语句进行解析、优化等操作后，"),t("code",[s._v("Server")]),s._v(" 层的执行器开始调用存储引擎层的接口，将一行行数据取出，当这些数据完全符合要求，则会放在结果集中，最后返回给 "),t("code",[s._v("MySQL")]),s._v(" 的客户端即可。")]),s._v(" "),t("h2",{attrs:{id:"基于主键即聚簇索引的执行流程"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#基于主键即聚簇索引的执行流程"}},[s._v("#")]),s._v(" 基于主键即聚簇索引的执行流程")]),s._v(" "),t("p",[s._v("首先我们先测试一下，取第一页的 10 条数据：")]),s._v(" "),t("div",{staticClass:"language-sql line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" t1 "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("order")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("by")]),s._v(" id "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("limit")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("耗时：0.027s")]),s._v(" "),t("p",[s._v("执行流程："),t("code",[s._v("select")]),s._v(" 后面带的是 星号，"),t("strong",[s._v("也就是取出获得行数据的所有字段信息")]),s._v("；"),t("code",[s._v("Server")]),s._v(" 层会调用 "),t("code",[s._v("innodb")]),s._v(" 引擎接口，在 "),t("code",[s._v("innodb")]),s._v(" 里的主键索引中获取第 0 到 10 条"),t("strong",[s._v("完整行的数据")]),s._v("，依次返回给 "),t("code",[s._v("Server")]),s._v(" 层，并放到 "),t("code",[s._v("Server")]),s._v(" 层的结果集中，返回给客户端看。")]),s._v(" "),t("p",[s._v("那如果我们把 offset 搞大点；为990000")]),s._v(" "),t("div",{staticClass:"language-sql line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" t1 "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("order")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("by")]),s._v(" id "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("limit")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("990000")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("耗时：0.366s")]),s._v(" "),t("p",[s._v("哈哈，耗时瞬间上来了；我们来看看这个语句的 "),t("code",[s._v("limit")]),s._v(" 的执行流程："),t("code",[s._v("Server")]),s._v(" 层执行器会调用 "),t("code",[s._v("innodb")]),s._v(" 存储引擎的接口，由于这次的 "),t("code",[s._v("offset")]),s._v(" 为 990000，会在 "),t("code",[s._v("innodb")]),s._v(" 里的主键索引中获取到第 0 到 （990000 + 10）条完整行数据，返回给 "),t("code",[s._v("Server")]),s._v(" 层之后根据 "),t("code",[s._v("offset")]),s._v(" 的值挨个抛弃，最后只留下 "),t("code",[s._v("size")]),s._v(" 条的数据，然后放到 "),t("code",[s._v("Server")]),s._v(" 层的结果集中，返回给客户端。")]),s._v(" "),t("p",[s._v("由此我们都可以猜出为什么后者的耗时那么长了，"),t("code",[s._v("limit 990000，10")]),s._v(" 比 "),t("code",[s._v("limit 0，10")]),s._v(" 更慢，是因为前者会取出 990000 + 10 条数据，然后丢弃前 990000 条数据；")]),s._v(" "),t("p",[s._v("既然知道了这个耗时地方，我们如何处理呢？")]),s._v(" "),t("p",[s._v("我们又知道我们取出的 990000 数据中是全字段数据，都没有用的，这又是一个耗时的操作；我们想办法"),t("strong",[s._v("只获取我们需要数据的全部字段值，不需要的字段尽量能少就少即可")]),s._v("；基于这个想法我们可以修改一下我们的 "),t("code",[s._v("SQL")]),s._v(" 语句")]),s._v(" "),t("div",{staticClass:"language-sql line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" t1 "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" id "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" t1 "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("order")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("by")]),s._v(" id "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("limit")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("990000")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("order")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("by")]),s._v(" id "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("limit")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("耗时：0.288s")]),s._v(" "),t("p",[s._v("优化了貌似也就这样哈哈，但是这也是一种优化的方案了。")]),s._v(" "),t("h2",{attrs:{id:"基于非主键索引的limit执行过程"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#基于非主键索引的limit执行过程"}},[s._v("#")]),s._v(" 基于非主键索引的limit执行过程")]),s._v(" "),t("p",[s._v("现在来看看非主键索引的 limit 执行过程；")]),s._v(" "),t("div",{staticClass:"language-sql line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" t1 "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("order")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("by")]),s._v(" person_id "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("limit")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("耗时：0.028s")]),s._v(" "),t("p",[s._v("执行流程："),t("code",[s._v("Server")]),s._v(" 层会调用 "),t("code",[s._v("innodb")]),s._v(" 存储引擎的接口，在 "),t("code",[s._v("innodb")]),s._v(" 里的非主键索引中获取到了第 0 条到 第 10 条数据对应的主键索引后，"),t("strong",[s._v("回表到主键索引中找到对应的完整行数据")]),s._v("，然后返回给 "),t("code",[s._v("Server")]),s._v(" 层，"),t("code",[s._v("Server")]),s._v(" 层将其放到结果集中，返回给客户端。")]),s._v(" "),t("p",[s._v("加大一下 "),t("code",[s._v("offset")]),s._v(" 来看看耗时：")]),s._v(" "),t("div",{staticClass:"language-sql line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" t1 "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("order")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("by")]),s._v(" person_id "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("limit")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4000000")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("耗时：3.445s")]),s._v(" "),t("p",[s._v("哈哈，下图请看，在偏移量很大时候，回表的次数很多，优化器甚至不用索引了，直接全表扫描；所谓优化器是我们执行器在执行 "),t("code",[s._v("SQL")]),s._v(" 之前，判断哪种执行计划代价更小，所以说，当数据量很大的时候，用 "),t("code",[s._v("limit offset")]),s._v(" 过大时，非主键索引查询非常容易变成全表扫描！！！"),t("a",{attrs:{href:"https://img-blog.csdnimg.cn/e7e5c8b049cb41a0bb5ab5bc3a9a144c.jpeg",target:"_blank",rel:"noopener noreferrer"}},[s._v("图片"),t("OutboundLink")],1)]),s._v(" "),t("p",[t("img",{attrs:{src:"https://img-blog.csdnimg.cn/e7e5c8b049cb41a0bb5ab5bc3a9a144c.jpeg",alt:"img"}})]),s._v(" "),t("p",[s._v("当然也可以去优化的：想法就是我们不仅"),t("strong",[s._v("只要我们所需要的记录的全部字符，不需要的就不要拷贝了，而且还要避免回表操作；")])]),s._v(" "),t("div",{staticClass:"language-sql line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" t1 t11"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" id "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" t1 "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("order")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("by")]),s._v(" person_id "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("limit")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4000000")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" t12 "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" t11"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" t12"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("耗时：0.938s")]),s._v(" "),t("p",[s._v("这里使用 "),t("code",[s._v("select id from t1 order by person_id limit 4000000,100")]),s._v(" 先走 "),t("code",[s._v("innodb")]),s._v(" 层的 "),t("code",[s._v("person_id")]),s._v(" 非主键索引中获取到 "),t("code",[s._v("id")]),s._v(" ，因为只拿 "),t("code",[s._v("id")]),s._v(" 所以避免了回表操作；然后获取到了 4000000 + 100 的数据（只含 "),t("code",[s._v("id")]),s._v(" 字段），然后抛弃了 前面的 4000000 条数据剩下最后的 100 条数据跟我们的 "),t("code",[s._v("t1")]),s._v(" 表做匹配，这样将符合条件的匹配到 100 条数据返回即可。")]),s._v(" "),t("p",[s._v("但是 方案都是没有绕开取前面 "),t("code",[s._v("offset")]),s._v(" 那么大的数据，都是取出来了只是抛弃了而已。。。")]),s._v(" "),t("p",[s._v("这就是所谓的 "),t("strong",[s._v("深度分页")]),s._v(" 问题了。")]),s._v(" "),t("h2",{attrs:{id:"深度分页问题"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#深度分页问题"}},[s._v("#")]),s._v(" 深度分页问题")]),s._v(" "),t("p",[t("strong",[s._v("一般都是要规避这个深度分页的问题的")])]),s._v(" "),t("h3",{attrs:{id:"如果想取出全表的数据"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#如果想取出全表的数据"}},[s._v("#")]),s._v(" 如果想取出全表的数据")]),s._v(" "),t("p",[s._v("可以将所有的数据根据 "),t("code",[s._v("id")]),s._v(" 主键进行排序完成后，然后分批获取，每次获取的时候都是上一次获取的最大 "),t("code",[s._v("id + 1")]),s._v(" 作为条件进行查询；")]),s._v(" "),t("p",[s._v("伪代码："),t("a",{attrs:{href:"https://mmbiz.qpic.cn/mmbiz_png/AnAgeMhDIiak10WxVpianzxZicJKTb4Kg74aQ9pYzcD7h1p2JhBEbtDQOsy68tk0OKDWBpTnssN2MZXhe7eWEbaBQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1",target:"_blank",rel:"noopener noreferrer"}},[s._v("图片"),t("OutboundLink")],1)]),s._v(" "),t("div",{staticClass:"language-sql line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[s._v("start_id:"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" {\n\t"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 取数据")]),s._v("\n\tdatas:"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" t1 "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" start_id "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("order")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("by")]),s._v(" id "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("limit")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 没数据，说明遍历结束")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("len")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("datas"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" {\n\t\t"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("break")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\t}\n\t"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 处理每次得到的结果")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("handler")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("datas"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 获取datas中最大的id 赋值给 start_id 进入下一个循环")]),s._v("\n\tstart_id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" getMaxIdFrom"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("datas"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n}\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br")])]),t("h3",{attrs:{id:"如果是给用户做分页展示"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#如果是给用户做分页展示"}},[s._v("#")]),s._v(" 如果是给用户做分页展示")]),s._v(" "),t("p",[s._v("有谁会去看 20 页乃至 100 页的数据呢？")]),s._v(" "),t("p",[s._v("所以我们可以参考一下谷歌的翻页功能："),t("a",{attrs:{href:"https://mmbiz.qpic.cn/mmbiz_png/AnAgeMhDIiak10WxVpianzxZicJKTb4Kg74gM3iaZRuXdvVsSSvSGuNKBJIS7PAmxXOA2TQxLymicualQCicK6Fsib8Ig/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1",target:"_blank",rel:"noopener noreferrer"}},[s._v("图片"),t("OutboundLink")],1),s._v("  只展示前 20 个分页；")]),s._v(" "),t("p",[s._v("如果可以的话 甚至可以考虑一下跳页？哈哈 上一页 下一页这样，就没有深度分页的问题了；包装一下？做成瀑布流，刷抖音的形式（"),t("a",{attrs:{href:"https://mmbiz.qpic.cn/mmbiz_png/AnAgeMhDIiak10WxVpianzxZicJKTb4Kg74VFAwXUWbh56o9oY4bdunFZJcHJ5BrVNbYUT3UJGOBB5icAAPIZfW8tQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1",target:"_blank",rel:"noopener noreferrer"}},[s._v("图片"),t("OutboundLink")],1),s._v("）？哈哈 都是可以的")]),s._v(" "),t("h2",{attrs:{id:"总结"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#总结"}},[s._v("#")]),s._v(" 总结")]),s._v(" "),t("ul",[t("li",[t("p",[s._v("深度分页问题可以优化，但是不能完美解决；只能通过"),t("strong",[s._v("限制查询数量")]),s._v("以及"),t("strong",[s._v("分批获取")]),s._v("的方式进行优化；")])]),s._v(" "),t("li",[t("p",[s._v("考虑一下原始的需求，结合业务去采取用哪一种分页方法；但是原则都是避开深度分页的场景的。")])])])])}),[],!1,null,null,null);t.default=r.exports}}]);